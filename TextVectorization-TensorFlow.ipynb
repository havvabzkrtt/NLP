{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtCRHk7d9pMK"
      },
      "source": [
        "# How to the TextVectorization Layer in TensorFLow (TensorFLow'da Metin Vektörleştirme Katmanı Nasıl Oluşturulur)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5pyat2_2uojp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L3RsgOluyiyU"
      },
      "outputs": [],
      "source": [
        "# Instanting\n",
        "text_vectorization = TextVectorization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iY8S5onGytHD"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    \"Bugün hava çok güzel\",\n",
        "    \"Ali, Efe ve Ece çay içecek\",\n",
        "    \"Selam söyle\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ngXk1j4zCbb"
      },
      "outputs": [],
      "source": [
        "# Creating the vocabulary with the adapt method.\n",
        "text_vectorization.adapt(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05I_y-XVzKDl",
        "outputId": "3a62d4aa-b4f2-4d50-cced-b6f61fb1b09e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('çok'),\n",
              " np.str_('çay'),\n",
              " np.str_('ve'),\n",
              " np.str_('söyle'),\n",
              " np.str_('selam'),\n",
              " np.str_('içecek'),\n",
              " np.str_('hava'),\n",
              " np.str_('güzel'),\n",
              " np.str_('efe'),\n",
              " np.str_('ece'),\n",
              " np.str_('bugün'),\n",
              " np.str_('ali')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's take a look at the vocabulary.\n",
        "text_vectorization.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEdicTg-zTQj",
        "outputId": "5a7a8e1e-31ca-4e50-fbd5-b996193eb0a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 6), dtype=int64, numpy=\n",
              "array([[12,  8,  2,  9,  0,  0],\n",
              "       [13, 10,  4, 11,  3,  7],\n",
              "       [ 6,  5,  0,  0,  0,  0]])>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data preprocessing with the layer\n",
        "vectorized_text = text_vectorization(data)\n",
        "vectorized_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3 cümle için 3 vektör oluşturuldu, ve kelimler indekslere göre sayısallaştırılıd. \n",
        "örneğin; \n",
        "\n",
        "Indeks saymaya 1'den başlanır. \"[UNK]\" sözlükte olmayan kelime içindir. \n",
        "- 12 -> 12. indeksteki kelime (\"bugün\")\n",
        "- 8 -> 8. indeksteki kelime (\"hava\")\n",
        "\n",
        "Bu kodda \"0\", cümle uzunluklarını eşitlemek için eklenen \"padding\" (doldurma) değerini ifade eder; yani gerçek bir kelimeye karşılık gelmez."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDU2o1dl7jI1"
      },
      "source": [
        "# Using the custom functions TextVectorization (Özel fonksiyonları kullanma TextVectorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BGgSQArYzpvE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aIx40gV406yD"
      },
      "outputs": [],
      "source": [
        "def standardization_fn(string_tensor):\n",
        "  lowercase=tf.strings.lower(string_tensor)\n",
        "  return tf.strings.regex_replace(\n",
        "      lowercase, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4T19MwA42RSq"
      },
      "outputs": [],
      "source": [
        "def split_fn(string_tensor):\n",
        "  return tf.strings.split(string_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LwuWFbHC2qKT"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    standardize=standardization_fn,\n",
        "    split = split_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GUlD9_573H9K"
      },
      "outputs": [],
      "source": [
        "text_vectorization.adapt(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXmh5k_s3P_s",
        "outputId": "ba39b903-e28b-412e-fa10-53112277cee4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([12, 11,  2,  9])>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Testing our layer with a text\n",
        "text = \"bugün ece çok güzel\"\n",
        "text_vectorization(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbTuG4QN8jtx"
      },
      "source": [
        "# Using TextVectorization in a model (TextVectorization'ı bir modelde kullanma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bu katman normalde CPU'da çalışır. Bu katman, tek başına kullanılırsa, modelimiz GPU'yu kullansa bile bu fonksiyon CPU'da çalışacağı için eğitim yavaş olur. Bu katmanı GPU'da çalıştırmak için ya model içerisinde ya da data pipeline (veri işleme pipeline) içerisine yerleştirilmelidir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU kullanılıyor mu?: []\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"GPU kullanılıyor mu?:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eğer çıktı boş bir liste ise ([]), GPU kullanılmıyor, yani CPU'dayız"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BPDzXpJW3wIq"
      },
      "outputs": [],
      "source": [
        "# Creating a Dataset object\n",
        "text_dataset = tf.data.Dataset.from_tensor_slices([\n",
        "    \"kedi\", \"aslan\", \"yunus\"\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB6sAoHf4Ydq"
      },
      "outputs": [],
      "source": [
        "# Creating the TextVectorization layer for pre-processing \n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=5000, # token sayısını sınırlama \n",
        "    output_sequence_length=4  # padding yapmak için dizi uzunluğu\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mqlU58R40P-"
      },
      "outputs": [],
      "source": [
        "# Creating the vocabulary\n",
        "vectorize_layer.adapt(text_dataset.batch(64)) # .batch(64) büyük veriler için tercih edilir "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sIxlLm-5RYq",
        "outputId": "1158826e-0f5c-427a-d143-25d2a7b7a895"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', np.str_('yunus'), np.str_('kedi'), np.str_('aslan')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorize_layer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nAMORijK5WTC"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
        "    vectorize_layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "input_data = np.array([\"kedi kartal aslan\", \"fok yunus\"], dtype=object) \n",
        "# Burada, input_data değişkenine metinleri içeren bir NumPy dizisi oluşturuluyor ve dtype=object ile her elemanın Python nesnesi (string gibi) olarak saklanması sağlanıyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[3, 1, 4, 0],\n",
              "       [1, 2, 0, 0]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(input_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"kartal\", 1 olarak indekslenmiş, çünkü sözlükte yok\n",
        "\"kedi\", 3 olarak indekslenmiş, çünkü sözlükte 3 \n",
        "\"fok\", 1 olarak indekslenmiş, çünkü sözlükte yok\n",
        "0 indeksleri padding için"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO9Zzm5eyUjAAYeJXfTbxU+",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
